{
  "repository": "arxiv",
  "total_papers": 3,
  "research_fields": [
    "Machine Learning"
  ],
  "scraped_at": "2025-07-25 12:46:35",
  "papers": [
    {
      "url": "http://arxiv.org/abs/1909.03550v1",
      "title": "Lecture Notes: Optimization for Machine Learning",
      "authors": [
        "Elad Hazan"
      ],
      "abstract": "Lecture notes on optimization for machine learning, derived from a course at\nPrinceton University and tutorials given in MLSS, Buenos Aires, as well as\nSimons Foundation, Berkeley.",
      "publication_date": "2019-09-08",
      "journal": "arXiv",
      "keywords": [
        "machine learning",
        "optimization"
      ],
      "citations_count": null,
      "doi": "arXiv:1909.03550",
      "pdf_url": "http://arxiv.org/pdf/1909.03550v1",
      "research_field": "Machine Learning",
      "institution": null,
      "scraped_at": "2025-07-25 12:46:35"
    },
    {
      "url": "http://arxiv.org/abs/1811.04422v1",
      "title": "An Optimal Control View of Adversarial Machine Learning",
      "authors": [
        "Xiaojin Zhu"
      ],
      "abstract": "I describe an optimal control view of adversarial machine learning, where the\ndynamical system is the machine learner, the input are adversarial actions, and\nthe control costs are defined by the adversary's goals to do harm and be hard\nto detect. This view encompasses many types of adversarial machine learning,\nincluding test-item attacks, training-data poisoning, and adversarial reward\nshaping. The view encourages adversarial machine learning researcher to utilize\nadvances in control theory and reinforcement learning.",
      "publication_date": "2018-11-11",
      "journal": "arXiv",
      "keywords": [
        "machine learning"
      ],
      "citations_count": null,
      "doi": "arXiv:1811.04422",
      "pdf_url": "http://arxiv.org/pdf/1811.04422v1",
      "research_field": "Machine Learning",
      "institution": null,
      "scraped_at": "2025-07-25 12:46:35"
    },
    {
      "url": "http://arxiv.org/abs/1707.04849v1",
      "title": "Minimax deviation strategies for machine learning and recognition with\n  short learning samples",
      "authors": [
        "Michail Schlesinger",
        "Evgeniy Vodolazskiy"
      ],
      "abstract": "The article is devoted to the problem of small learning samples in machine\nlearning. The flaws of maximum likelihood learning and minimax learning are\nlooked into and the concept of minimax deviation learning is introduced that is\nfree of those flaws.",
      "publication_date": "2017-07-16",
      "journal": "arXiv",
      "keywords": [
        "machine learning"
      ],
      "citations_count": null,
      "doi": "arXiv:1707.04849",
      "pdf_url": "http://arxiv.org/pdf/1707.04849v1",
      "research_field": "Machine Learning",
      "institution": null,
      "scraped_at": "2025-07-25 12:46:35"
    }
  ]
}